#!/usr/bin/env python3
"""
DeepSeek CLI å¯¹è¯æµ‹è¯•å·¥å…·

åŠŸèƒ½ï¼š
- å‘½ä»¤è¡Œäº¤äº’å¼å¯¹è¯
- æ”¯æŒå¤šè½®å¯¹è¯
- è‡ªåŠ¨ä¿å­˜å¯¹è¯å†å²
- æ”¯æŒé€€å‡ºå‘½ä»¤
- é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶

ä½¿ç”¨æ–¹æ³•ï¼š
1. ç¡®ä¿å·²é…ç½® .env æ–‡ä»¶ä¸­çš„ DEEPSEEK_API_KEY
2. è¿è¡Œï¼špython cli_chat.py
3. è¾“å…¥é—®é¢˜è¿›è¡Œå¯¹è¯
4. è¾“å…¥ 'exit' æˆ– 'quit' é€€å‡º
"""

import os
import sys
from dotenv import load_dotenv
from limbic_flow.core.ai.adapters.deepseek import DeepSeekLLM
from limbic_flow.core.ai.base import LLMConfig, Message, MessageRole

def load_config():
    """åŠ è½½é…ç½®"""
    load_dotenv()
    
    api_key = os.getenv("DEEPSEEK_API_KEY")
    if not api_key:
        print("é”™è¯¯: æœªé…ç½® DEEPSEEK_API_KEY ç¯å¢ƒå˜é‡")
        print("è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® DEEPSEEK_API_KEY=your_api_key")
        sys.exit(1)
    
    return LLMConfig(
        model=os.getenv("DEEPSEEK_MODEL", "deepseek-chat"),
        api_key=api_key,
        base_url=os.getenv("DEEPSEEK_BASE_URL", "https://api.deepseek.com/v1"),
        temperature=float(os.getenv("LLM_TEMPERATURE", "0.7")),
        max_tokens=int(os.getenv("LLM_MAX_TOKENS", "1024")),
        timeout=int(os.getenv("LLM_TIMEOUT", "30"))
    )

def create_llm_instance(config):
    """åˆ›å»º LLM å®ä¾‹"""
    try:
        llm = DeepSeekLLM(config)
        print(f"âœ… æˆåŠŸè¿æ¥åˆ° DeepSeek API")
        print(f"ï¿½ model: {config.model}")
        print(f"ğŸŒ base_url: {config.base_url}")
        print()
        return llm
    except Exception as e:
        print(f"âŒ è¿æ¥å¤±è´¥: {str(e)}")
        sys.exit(1)

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("DeepSeek CLI å¯¹è¯æµ‹è¯•å·¥å…·")
    print("=" * 60)
    print("æç¤º: è¾“å…¥é—®é¢˜è¿›è¡Œå¯¹è¯ï¼Œè¾“å…¥ 'exit' æˆ– 'quit' é€€å‡º")
    print("=" * 60)
    print()
    
    # åŠ è½½é…ç½®
    config = load_config()
    
    # åˆ›å»º LLM å®ä¾‹
    llm = create_llm_instance(config)
    
    # å¯¹è¯å†å²
    conversation_history = []
    
    try:
        while True:
            # è·å–ç”¨æˆ·è¾“å…¥
            user_input = input("ä½ : ").strip()
            
            # æ£€æŸ¥é€€å‡ºå‘½ä»¤
            if user_input.lower() in ["exit", "quit", "é€€å‡º", "é€€å‡º()"]:
                print("å†è§ï¼")
                break
            
            # è·³è¿‡ç©ºè¾“å…¥
            if not user_input:
                continue
            
            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
            conversation_history.append(Message(role=MessageRole.USER, content=user_input))
            
            # å‘é€è¯·æ±‚
            print("DeepSeek: ", end="", flush=True)
            
            try:
                # è°ƒç”¨ API
                response = llm.chat(conversation_history)
                
                # æ‰“å°å“åº”
                print(response.content)
                print()
                
                # æ·»åŠ åŠ©æ‰‹å›å¤åˆ°å†å²
                conversation_history.append(Message(role=MessageRole.ASSISTANT, content=response.content))
                
                # æ‰“å°ä½¿ç”¨é‡ï¼ˆå¦‚æœæœ‰ï¼‰
                if response.usage:
                    print(f"ğŸ’¡ ä½¿ç”¨é‡: {response.usage['total_tokens']} tokens")
                    print()
                    
            except Exception as e:
                print(f"\nâŒ é”™è¯¯: {str(e)}")
                print("è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ– API Key æ˜¯å¦æ­£ç¡®")
                print()
                
                # ä»å†å²ä¸­ç§»é™¤æœ€åä¸€æ¡æ¶ˆæ¯ï¼ˆç”¨æˆ·è¾“å…¥ï¼‰
                if conversation_history:
                    conversation_history.pop()
                    
    except KeyboardInterrupt:
        print("\n\nå†è§ï¼")
        sys.exit(0)

if __name__ == "__main__":
    main()